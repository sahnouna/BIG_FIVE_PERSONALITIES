\section{Implementation/Simulation}
TODO: Show the implementation. The goal of this section is to show and explain the most important
parts of the code. Listing the code with highlighting and possibly line numbering is essential.
Explain the code by referring to line numbers, function calls and variable names.
Leave out trivial parts (initialization, parameter-tuning, etc...).
\newline
\underline{Data Preparation \href{https://github.com/Matthias2193/SPL/tree/master/Big5GritDataPreparation}{\includegraphics[scale = 0.06]{Figures/qletlogo.pdf}} :} 
\newline 
This Quantlet translates data sets containing answers to a 50 item questionnaire into a data frame with the values of the personality traits according to the evaluation key. Optionally it can also deal with a data set from a questionnaire about grit. However, the data needs to contain the 50 items of the personality test. The order in which these answers are given does not matter since they are going to be reordered in the process of data cleaning.
\newline
The data "clean" function \href{https://https://github.com/Matthias2193/SPL/commit/7a9a8e8f543d93d635e4eeefad63280a26be99ad}{\includegraphics[scale = 0.06]{Figures/qletlogo.pdf}Big5GritDataPreparation} takes the name of a data set, a boolean variable whether the data contains grit questionnaire and a survey date as parameters. This function can deal with excel data and data in the .csv format. It converts some of the numerical variable into factors and reorders the column. Before columns are converted the function checks whether they are null to prevent errors when trying to convert non existing columns. Unrealistic age values (greater than 100 or lower than 10) are also handled here. If a survey data is specified all age values larger than survey data - 101 are replaced by the absolute value of the survey date minus the age value. This approach is taken since a lot of people enter their birth year instead of their age. With this method we still get their actual age. For the remaining unrealistic age values a prediction model is build on the remaining variables and their age is predicted. The predicted at is rounded to the nearest integer. This approach lets us estimate a persons age so we are hopefully closer to the real value than if we just guessed or taken the mean/median. However, using a prediction model is prone to errors especially if used without specifying the input manually. Therefore, if there is an error during the prediction process the remaining unrealistic age values are replaced by random samples from the realistic ones. This way the guessed values resemble the distribution of the observed ones.
\newline
The "getResults" function \href{https://github.com/Matthias2193/SPL/blob/96a61ea2293d61c99c075877aca3accc1c847a22/Big5GritDataPreparation/Big5GritDataPreparation.R#L161-L195}{\includegraphics[scale = 0.06]{Figures/qletlogo.pdf}Big5GritDataPreparation} transforms the questionnaire answers into the actual values of the personality traits and adds them to the data frame.
\newline
"getDataSetWithBig5" and "getGritDF" are the main methods that transform and return the Big 5 or Grit data set respectively. The columns of the returned data frames are always ordered with first the extra data (age, gender, nationality,...) then the 5 personality trait, and at the end Grit.
\newline
The "getCombinedData" function is basically a combination of the previous ones. This function only works if you have both Big 5 and Grit data and then combines them into one data frame omitting all columns that are only present in the latter. This method is used to combine our two data sets to give us more observations for analysis. It is however fairly specific to our case and will most likely not work properly with other data.
\newline
\newline
\underline{Data Preparation Analysis \href{https://github.com/Matthias2193/SPL/blob/master/SPL_Big5DataPreparationAnalysis/SPL_Big5DataPreparationAnalysis.R}{\includegraphics[scale = 0.06]{Figures/qletlogo.pdf}} :} 
In this Quantlet we test how well principal component analysis and factor analysis estimate the scaled values obtained by using the evaluation key. Throughout this analysis the data worked with will often be just the answers to the questionnaires. To that end the columns will be selected using to numbers. 'Start' which is set to "which(colnames(data) == "E1")" and 'end' which is set to 'start + 49'. This is possible since the columns where sorted in this specific way during data cleaning.
\newline
The first step is estimating the correct number of pcs or factors to extract. This is done in several ways.
The first way is using the \href{https://www.rdocumentation.org/packages/psych/versions/1.8.4/topics/VSS}{vss} function implemented in R, which estimates the number of factors in a factor analysis. Another method is to do a parallel analysis to find both a good number for factors and pcs. The last method implemented is to do a simple PCA and to draw a screeplot. \href{https://github.com/Matthias2193/SPL/blob/3d1d23303132ad8092531f9474fbf78f5a8df3c5/SPL_Big5DataPreparationAnalysis/SPL_Big5DataPreparationAnalysis.R#L20-L54}{\includegraphics[scale = 0.06]{Figures/qletlogo.pdf}SPL\_Big5DataPreparationAnalysis}.
\newline
In the code there are 3 functions implemented to extract the values via PCA as well as 1 function that uses factor analysis \href{https://github.com/Matthias2193/SPL/blob/3d1d23303132ad8092531f9474fbf78f5a8df3c5/SPL_Big5DataPreparationAnalysis/SPL_Big5DataPreparationAnalysis.R#L10-L16}{\includegraphics[scale = 0.06]{Figures/qletlogo.pdf}SPL\_Big5DataPreparationAnalysis}. Those 4 functions all take a cleaned data frame as input and return a new data frame in which the questionnaire answers are replaced by the estimated values for the personality traits. Non-questionnaire columns remain unchanged. The functions for PCA differ in the PCA function they use. The 3 implemented are: \href{http://www.personality-project.org/r/html/principal.html}{principal}, \href{https://stat.ethz.ch/R-manual/R-devel/library/stats/html/prcomp.html}{prcomp} and \href{https://stat.ethz.ch/R-manual/R-devel/library/stats/html/princomp.html}{princomp}.  
\newline
Next the results of 'prcomp' and 'princomp' are compared in 2 ways. First, a screeplot is drawn for both results and then their centers and standard deviations are compared.
\newline
The main comparison of PCA, factor analysis and the evaluation key is done in two functions: 'compareDensities' and 'compareDifferences' \href{https://github.com/Matthias2193/SPL/blob/f6c320279a478642e8a87020ac48029a48624933/SPL_Big5DataPreparationAnalysis/SPL_Big5DataPreparationAnalysis.R#L78-L117}{\includegraphics[scale = 0.06]{Figures/qletlogo.pdf}SPL\_Big5DataPreparationAnalysis}. Both function take the name of a data file as input. Then both transform the questionnaire answers to personality traits using the evaluation key, factor analysis and PCA ('princomp'). 'compareDensities' then uses a for loop to go through a vector with the names of the personality traits and draws a a plot containing the density distribution of all 3 methods for each personality trait.
\newline
'compareDifferences' simply compares the average difference between factor analysis and evaluation key vs. PCA and evaluation key.
\newline
In the data cleaning part it was mentioned that there is an option to combine 2 data set in order to have more observations. This is only possible if both data sets don't have overlap. Otherwise you would have the several observations twice in the combined data set. 
\newline
The last part of this analysis is a test to check for overlap between 2 datasets. To do this the 2 data sets are merged by the traits or by the remaining columns. The 'nrow' function then gives the number of matching pairs in the 2 data sets.  
\newline
\newline
\underline{Correlation Analysis \href{https://github.com/Matthias2193/SPL/blob/master/SPL_Big5CorrelationAnalysis/SPL_Big5CorrelationAnalysis.R}{\includegraphics[scale = 0.06]{Figures/qletlogo.pdf}} :} 
\newline
This Quantlet shows the correlation first just between the five personality traits in a normal corrplot. Then it adds age and gender and displays the results in two mixed corrplots. Once unordered and once ordered by the angular order of the eigenvectors (AOE).
\newline
\underline{Cluster Analysis \href{https://github.com/Matthias2193/SPL/blob/master/SPL_Big5ClusterAnalysis/SPL_Big5ClusterAnalysis.R}{\includegraphics[scale = 0.06]{Figures/qletlogo.pdf}} :} 
\newline
The goal of this Quantlet is to do some basic clustering on the personality traits plus age. First the data is clustered using k-Means with 2 to 5 clusters. Each time a plot is drawn displaying the results. To do this in a 2-dimensional space the dimensions are reduced using PCA during the plotting process. Additionally the mean values for the personality traits and age are printed out for each cluster after each clustering process. To do this 4 time a for-loop is used. \href{https://github.com/Matthias2193/SPL/blob/5c17336568167689696460c9166539babe69ee23/SPL_Big5ClusterAnalysis/SPL_Big5ClusterAnalysis.R#L10-L22}{\includegraphics[scale = 0.06]{Figures/qletlogo.pdf}SPL\_Big5ClusterAnalysis}. This is done to give and initial overview over how different numbers of clusters will look and possibly provide an intuitive idea of the best number of clusters to actually use.
\newline
There are also 3 different tests implemented to estimate the best number of clusters to use. Those 3 methods are: 'Elbow methods', 'average silhouette' and 'GAP\_stat'. The 2 methods used for clustering are k-Means and 'partition around medoids' (PAM). Since clustering can be computing intensive the clustering is not done on the entire data set. Using the 'sample' function 2000 random elements of the dataset are selected for the analysis. For 'GAP\_stat' this number goes down to 1000, but the process might still take some time especially for (PAM). All of those test are run using the \href{https://www.rdocumentation.org/packages/factoextra/versions/1.0.5/topics/fviz_nbclust}{fviz\_nbclust} function.
